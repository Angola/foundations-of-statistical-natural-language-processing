# まえがき
- WWWなどの巨大なテキストコーパスの成立を背景に、1990年代以降言語学では定量的な研究が発展してきた。
- 扱う内容
  - 確率論
  - 情報理論
  - 統計学
  - 統計的自然言語処理
- 扱わない内容
  - 音声認識
  - 境界にあるアルゴリズムなど

# 本書の使い方
本書は4編に分かれる。
1. 前提知識  
  数学・言語学の基礎知識
2. 語  
  連語、n-グラムモデル、語義曖昧性解消、語彙獲得
3. 文法  
  マルコフモデル、タグ付け、確率文脈自由文法、確率的構文解析
4. 応用と技法  
  統計的アライメントと機械翻訳、クラスタリング、情報検索、テキスト分類

# 1章　導入
伝統的言語学の概略と統計的方法論の導入

言語には「規則」がある。「すべての文法には漏れがある」（サピア）  
規則の解明のため、なぜ統計的方法がとられるのか。どのように取り組むべきか。

## 1.1 言語に対する合理主義的方法論と経験主義的方法論
- 合理主義者  
  - 人間には生得的な言語能力がある。  
  「人間の心の中の知識の重要な部分は感覚刺激によって導かれるのではなく、事前に、おそらくは遺伝的な継承によって、決定されている」(p.5)  
  ノーム・チョムスキーが有名。「刺激の不足」の問題  
  - 人工知能の方法で例えると、人間の頭脳のような初期知識や推論機構を手作業で設定するという方針  
  - 人間の心的な言語、言語能力を研究する。  
  - カテゴリカルに考える。
- 経験論者  
  - ここでの経験論は「タブラ・ラサ」ではなく程度の問題。  
  合理主義者が主張するほどには、人間の脳は固有の認知機構を持ってはいない。  
  パターン認識や一般化によって自然言語を学習している。  
  - 統計的、機械学習の方法を適用できる。  
  - テキストの集合、コーパスを用いて研究をする。
  - 確率論で考える。

## 1.2 科学的意義
近年統計的手法が発展したのは、それが実用的な問題に対処できるため。

### 1.2.1 言語学が答えるべき質問
1. 人はどんなことをどんな形で話しているのか？(p.8)  
  言語の構造に関する問い
1. それらのことは、世界について何を述べ、訊ね、もとめているのか？(p.8)  
  意味論や語用論、談話

統計的言語処理ではコーパスも用いたパターン認識によってこれらの質問に答える。  
まずは第一の質問から始める。
- 伝統的な言語学の考え  
  抽象化した「言語能力文法」を考える。  
  どのような文な「文法的」であり、どの文が「非文法的」なのか、「文法性」という概念から文を分類する。  
  ex) Colorless green ideas sleep furiously. (チョムスキー)
- 反論  
  1. 文を文法的／非文法的の二分割にするのは無理がある。
  2. 文や文のタイプが使われる頻度も重要

### 1.2.2 カテゴリカルでない言語現象
言語の歴史的変化  
単語の使われ方は、文法的にも変化する。  
変化の過程では、用法が混在するケースが多々ある。  
ex) while, near, kind of

### 1.2.3 確率的現象としての言語と認知
人間の認知は確率的。よって言語も確率的。  
ただ「既存の統計的自然言語処理は低いレベルの文法的処理に集中している。」  
<-「意味』の定義が曖昧であるせい。  
  記号表現として扱えばDBで扱える。  
  または文脈の分布の中に意味が存在すると考える。  
  ウィトゲンシュタイン「意味の使用理論」  
  「ある語の意味はその仕様の環境によって定義される」(p.16)

## 1.3 言語の曖昧性：なぜ自然言語処理は困難なのか
「誰が何を誰にしたか」にこたえられる程度まで、テキストの構造を明らかにしなければならない。  
- 古典的な構文解析システム  
  構文木：文が長くなるほど曖昧性により多数の構文木を生み出すことになる。  
  ->人手で制約や規則を構築するのは大変。比喩にも弱い。  
    ex)選択制限
- 統計的言語処理
  「コーパスから語彙的構造的選好を自動的に学習する」(p.18)  
  曖昧性に強い。人的努力が減る。

## 1.4 汚れ仕事

### 1.4.1 言語資源  
実際にどうやって研究を進めて行くのか。  
まず、「言語資源」を入手する必要がある。  
種々のコーパスが存在する。  
ex)ブラウンコーパス（注釈つき）、カナダ議会議事録（二言語コーパス）
cf)京都大学のコーパス。Wikipedia、ライブドアブログのコーパス

### 1.4.2 単語数
『トム・ソーヤー』を例に単語について考える。
- 最も多く現れている後はなんだろうか？（表1.1 p.20）  
  機能語が多くあらわれる。
- いくつの語が含まれている？
   - 語トークン count(単語)　71,370
   - 語タイプ count(distinct(単語)) 　8.018  
     子供向けだから少なめ？
- どのくらいの数の語がどのくらいの頻度で現れているか？（表1.2 p.21）  
  最もよく現れる100語が語トークンの半分を占める。  
  半分の語タイプは一回しか現れていない。  
  -> 統計的に扱うのが難しい。

### 1.4.3 ジップの法則など
ジップ「人間のふるまいと最小労力の原理」：「人々はその予測される仕事の割合の平均を最小化するように行動する」(p.22)  
-> ジップの見つけた経験則

- コーパスの中のある後の出現頻度をf、出現頻度の順位をrとすると、fは1 / r に比例する。  
  -> f * r = k であるような定数ｋが存在する。(表1.3 p.23)
  ランキングTop3は大分ずれる。100位前後だとやや膨れる。  
    -> データは極めて疎である。  
  より適合的な改良式もある。 f = P(r + ρ) ^ -B  （マンデルブロ）
- ある後の持つ意味の数をmとすると、m は √f に比例する
- テキストの中のある語の出現の間隔の大きさをI、その頻度をFとすると、Fは I^-p に比例する。（pは1~1.3s）  
  「言い換えると、たいていの場合、内容語はその語の別の出現の近くに出現する」

べき法則の重要性  
ランダムに語を生成したとしても、べき法則に従う。  
-> 本質的なのは、ほとんどすべての語は稀にしか現れないので、統計的処理が難しいということ。

### 1.4.4 連語
「連語とは、任意の言い回しもしくは一般に受け入れられている用法で、それ全体として認知され、その部分の単なる合計以上の何かを持つようなもの」(p.27)  
ex) disk drive, make up, bacon and eggs  
連語を探すため、テキストから最も多く現れる2語を探す。->バイグラム(p.28)   
-> あまり良くない。フィルタリングなど修正方法もある。5章で引き続き見ていく。  

### 1.4.5 コンコーダンス
KWIC(文脈付きキーワード)により統語フレームを探す。(図1.3 p.30)  
ex) トム・ソーヤーの中での 'showed' の使われ方。

## 1.5 さらに学ぶために
参考文献の紹介

## 1.6 練習問題
省略